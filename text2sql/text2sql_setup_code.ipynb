{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "connection_parameters = json.load(open('../connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "# Add a query tag to the session.\n",
    "session.query_tag = {\"origin\":\"sf_sit-is\", \n",
    "                     \"name\":\"spcs_call_center\", \n",
    "                     \"version\":{\"major\":1, \"minor\":0},\n",
    "                     \"attributes\":{\"is_quickstart\":1, \"source\":\"notebook\", \"vignette\":\"text2sql\"}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build docker image and push the image to image registry\n",
    "\n",
    "- Run the below code from terminal. Set your working directory to text2sQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Run below commands from a terminal. Update the ORGNAME-ACCTNAME with your account info and alsp update the IMAGE_REPOSITORY, DATABASE , SCHEMA NAME and username -->\n",
    "\n",
    "```\n",
    "cd text2sql\n",
    "\n",
    "docker build --no-cache --platform linux/amd64 -t ORGNAME-ACCTNAME.registry.snowflakecomputing.com/llmdemo/public/images/audiollm:latest . \n",
    "\n",
    "docker login ORGNAME-ACCTNAME.registry.snowflakecomputing.com -u <username>\n",
    "\n",
    "docker push ORGNAME-ACCTNAME.registry.snowflakecomputing.com/llmdemo/public/images/audiollm:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the Compute Pool and BIND SERVICE ENDPOINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below command in Snowsight as <b>AccountAdmin</b> . Replace role SPCS_PSE_ROLE with your own role name if you have created with different name.\n",
    "\n",
    "``` sql\n",
    "USE ROLE ACCOUNTADMIN;\n",
    "\n",
    "CREATE COMPUTE POOL PR_GPU_7\n",
    "  MIN_NODES = 1\n",
    "  MAX_NODES = 1\n",
    "  INSTANCE_FAMILY = GPU_NV_M\n",
    "  AUTO_RESUME = FALSE\n",
    "  INITIALLY_SUSPENDED = FALSE\n",
    "    COMMENT = 'For text2sql' ;\n",
    "\n",
    "GRANT USAGE, MONITOR ON COMPUTE POOL PR_GPU_7 TO ROLE SPCS_PSE_ROLE;\n",
    "\n",
    "-- Execute the below command if you have not used audio2text container\n",
    "GRANT BIND SERVICE ENDPOINT ON ACCOUNT TO ROLE SPCS_PSE_ROLE ;\n",
    "\n",
    "-- Below network rule and External Access INtegration is used to download the whisper mode.\n",
    "\n",
    "-- You need to execute the below two commands only once for all the SPC services that you will be creating. If you have already created the below rule and EAI, ignore execute the below two commands.\n",
    "\n",
    " CREATE NETWORK RULE allow_all_rule\n",
    "    TYPE = 'HOST_PORT'\n",
    "    MODE= 'EGRESS'\n",
    "    VALUE_LIST = ('0.0.0.0:443','0.0.0.0:80');\n",
    "\n",
    "CREATE EXTERNAL ACCESS INTEGRATION allow_all_eai\n",
    "  ALLOWED_NETWORK_RULES = (allow_all_rule)\n",
    "  ENABLED = true;\n",
    "\n",
    "GRANT USAGE ON INTEGRATION allow_all_eai TO ROLE SPCS_PSE_ROLE;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3. Creating Text2SQL SPC Service\n",
    "\n",
    "Update th YAML to change the image value before executing the below put command\n",
    "\n",
    "image: ORGNAME-ACCTNAME.registry.snowflakecomputing.com/pr_llmdemo/public/image_repo/audiollm:latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PutResult(source='llm-text2sql.yaml', target='llm-text2sql.yaml.gz', source_size=652, target_size=358, source_compression='NONE', target_compression='GZIP', status='UPLOADED', message='')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "session.file.put(\"./llm-text2sql.yaml\", \"@specs\",auto_compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the service. EXTERNAL_ACCESS_INTEGRATIONS(ALLOW_ALL_EAI) is created in audio2text/audio2text_setup_code.ipynb\n",
    "session.sql('''\n",
    "create service llama_text2sql_svc\n",
    "in compute pool PR_GPU_7\n",
    "from @specs\n",
    "spec='llm-text2sql.yaml'\n",
    "EXTERNAL_ACCESS_INTEGRATIONS = (ALLOW_ALL_EAI)\n",
    "            ''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'SUSPENDED',\n",
       " 'message': 'Suspended',\n",
       " 'containerName': 'text2sql-container',\n",
       " 'instanceId': '0',\n",
       " 'serviceName': 'LLAMA_TEXT2SQL_SVC',\n",
       " 'image': 'sfseeurope-us-west-ccarrero-452.registry.snowflakecomputing.com/pr_llmdemo/public/images/audiollm:latest',\n",
       " 'restartCount': 0,\n",
       " 'startTime': ''}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Check the status of service\n",
    "import ast\n",
    "res=session.sql(''' \n",
    "SELECT SYSTEM$GET_SERVICE_STATUS('llama_text2sql_svc',1)\n",
    "''').collect()[0][0]\n",
    "ast.literal_eval(res)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Accessing Jupyter Lab Endpoints\n",
    "Wait for the status of the service to be Running before moving to next step. \n",
    "\n",
    "Run the below query to get the api endpoint for the <b> jupyter lab </b>. Get the <b>ingress_url </b>(this endpoint will launch jupyter notebook running Snowpark Containers)  from the below query output.\n",
    "\n",
    "Ouput that you would get after running the below query.\n",
    "\n",
    "Row(name='llm-audio-ep', port=8888, protocol='TCP', ingress_enabled='true', ingress_url='test123-us-west-ccarrero-452.snowflakecomputing.app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='llm-audio-ep', port=8888, protocol='TCP', ingress_enabled='true', ingress_url='gmtqocnn-sfseeurope-us-west-ccarrero-452.snowflakecomputing.app')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('''show endpoints in service llama_text2sql_svc;\n",
    "            ''').collect()[0]\n",
    "\n",
    "# Row(name='llm-audio-ep', port=8888, protocol='TCP', ingress_enabled='true', ingress_url='test123-us-west-ccarrero-452.snowflakecomputing.app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perform the following action on the Jupyter lab which is accessible from the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1. Open the terminal in the JupyterLab(which is running in Snowpark Containers) and run the below shell script  </b>\n",
    "\n",
    "- sh [./download_model.sh](https://github.com/Snowflake-Labs/sfguide-call-centre-analytics-with-snowflake-cortex-and-spcs/blob/main/text2sql/download_model.sh)\n",
    "\n",
    "This file will download the Numberstation model from hugging face and downloads to the stage which is mounted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2. Run the [FineTuneModel.ipynb](https://github.com/Snowflake-Labs/sfguide-call-centre-analytics-with-snowflake-cortex-and-spcs/blob/main/text2sql/FineTuneModel.ipynb)  </b>\n",
    "\n",
    "* Execute each cell by cell where we are fine tuning the model as well with our own dataset.\n",
    "\n",
    "* After executing the last cell you will be running a fast api service which will expose the Number station LLM as a api endpoint.\n",
    "\n",
    "><b> PS </b> : You need to execute step 1 and 2 only one time and from next time after you start the Snowpark service, run the below command from the terminal launched in the jupyter lab:\n",
    "\n",
    " * <b> sh [RunFastAPI.sh](https://github.com/Snowflake-Labs/sfguide-call-centre-analytics-with-snowflake-cortex-and-spcs/blob/main/text2sql/RunFastAPI.sh) </b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Execute the below commands to create the service function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql('''CREATE OR REPLACE FUNCTION text2sql(text TEXT)\n",
    "RETURNS VARIANT\n",
    "SERVICE=llama_text2sql_svc\n",
    "ENDPOINT=api\n",
    "AS '/text2sql\n",
    "            ''').collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the function\n",
    "session.sql('''\n",
    "select text2sql('What is the distinct purpose of the calls in the last month?')::string;\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark_3_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
